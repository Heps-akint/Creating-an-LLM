{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os # for interacting with the os\n",
    "import lzma # for hadling .XZ  files\n",
    "from tqdm import tqdm #for displaying a progress bar to show how fast the script executes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the .xz files from the the directory of the data\n",
    "def xz_files_in_directory(directory): #takes directory as input\n",
    "    files = []\n",
    "    for filename in os.listdir(directory): #os.listdr gets the filename.\n",
    "        if filename.endswith(\".xz\") and os.path.isfile(os.path.join(directory, filename)): #This is used to check if each one of the files ends in .xz and that the file is not a directory etc\n",
    "            files.append(filename) #if the file is in the directory, and is a file, it appends the list with the filename\n",
    "    return files    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring variables\n",
    "folder_path = \"/Users/hephzibah/Downloads/openwebtext\" #This is the filepath of the .xz files. Change to filepath of .xz data file installation.\n",
    "output_file_training = \"training_split.txt\" #The pattern for the filenames in case we want to have more than one.\n",
    "output_file_validation = \"validation_split.txt\" #The pattern for the filenames in case we want to have more than one.\n",
    "vocab_file = \"vocab.txt\" #Where we will save our vocabulary. This pushes the vocab into files since we can't have them all loaded into RAM.\n",
    "\n",
    "\n",
    "files = xz_files_in_directory(folder_path)\n",
    "total_files = len(files)\n",
    "\n",
    "#Calculates the split indices\n",
    "split_index = int(total_files * 0.9) # 90% of data for training\n",
    "files_training = files[:split_index]\n",
    "files_validation = files[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 18549/18549 [40:13<00:00,  7.68it/s]\n",
      "100%|███████████████████████████████████████| 2061/2061 [04:16<00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41min 12s, sys: 2min 38s, total: 43min 51s\n",
      "Wall time: 44min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Data Processing and training/validation splitting\n",
    "#Only run if enough disk space is availabe for training and validation files.\n",
    "\n",
    "#Process the files for training a validation seperately\n",
    "vocab = set()\n",
    "\n",
    "#Processing the .xz training files. \n",
    "with open(output_file_training, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for filename in tqdm(files_training, total=len(files_training)): #for each output file, process max_count files\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with lzma.open(file_path, \"rt\", encoding=\"utf-8\") as infile: #for each files, we'll open it\n",
    "                text = infile.read() #Reads the contents of the files\n",
    "                outfile.write(text) #writes the contents of the files into the current output file\n",
    "                characters = set(text) #creating character set\n",
    "                vocab.update(characters) #add any unique characters to the character set\n",
    "\n",
    "#Processing the .xz validation files. \n",
    "with open(output_file_validation, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for filename in tqdm(files_validation, total=len(files_validation)): #for each output file, process max_count files\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with lzma.open(file_path, \"rt\", encoding=\"utf-8\") as infile: #for each files, we'll open it\n",
    "                text = infile.read() #Reads the contents of the files\n",
    "                outfile.write(text) #writes the contents of the files into the current output file\n",
    "                characters = set(text) #creating character set\n",
    "                vocab.update(characters) #add any unique characters to the character set\n",
    "\n",
    "# Writing the vocabulary to vocab.txt\n",
    "with open(vocab_file, \"w\", encoding=\"utf-8\") as vfile:\n",
    "    for char in vocab:\n",
    "        vfile.write(char + '\\n') #Write all the characters in the cocab into the vocab file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
